```{r}
library(tidyverse)
library(stringdist)
```

```{r}
dat.linux <-
  read.csv("in/cache/linux.csv") |>
  tibble() |>
  add_column(corpus = "linux")

dat.collins <-
  read.csv("in/cache/collins.csv") |>
  tibble() |>
  add_column(corpus = "collins") |>
  mutate(
    start = start + 1, # Made this column zero-indexed by accident :)
    end = end + 1
  )

dat.nwl <-
  read.csv("in/cache/NWL2020.csv") |>
  tibble() |>
  add_column(corpus = "nwl")
# Defer binding + memory allocation until last possible second --
# no clue if that actually does anything
dat.all <- function() {
  rbind(
    dat.linux,
    dat.collins,
    dat.nwl
  )
}
```

```{r}
dat.all() |>
  # slice_sample(prop = 1) |>
  # group_by(corpus) |>
  # add_count(length) |>
  ggplot(aes(x = length, fill = corpus)) +
  geom_bar() +
  scale_x_continuous(breaks = 5:21) +
  scale_y_continuous(trans = "log10") +
  theme(panel.grid.minor.x = element_blank())
```

```{r}
# most common pairings, in original
# lexical order
dat.all() |>
  filter(end == length) |>
  select(x, y, split_x, split_y, length, end) |>
  count(split_x, split_y) |>
  arrange(desc(n))
```

```{r}
suffixes <- dat.all() |>
  filter(end == length)

suffix_counts <- c(
  suffixes$split_x,
  suffixes$split_y
) |>
  table() |>
  data.frame() |>
  tibble() |>
  arrange(desc(Freq)) |>
  rowid_to_column(var = "rank")

## Interesting:
# the top 6 suffixes are all
# declensions: es, ed, er, (i)ng, (i)on, ly
suffix_counts |>
  ggplot(aes(x = log10(rank), y = log10(Freq))) +
  geom_point() +
  scale_x_continuous(limits = c(0, 5)) +
  scale_y_continuous(limits = c(0, 5)) +
  coord_fixed()
```

```{r}
# let's take a look at that more generally

splits_by_type <- dat.all() |>
  mutate(
    type = case_when(
      start == 1 ~ "prefix",
      end == length ~ "suffix",
      TRUE ~ "middle"
    )
  )

rbind(
  splits_by_type |> select(split = split_x, type),
  splits_by_type |> select(split = split_y, type)
) |>
  count(split, type) |>
  group_by(type) |>
  mutate(
    rank = rank(-n, ties.method = "first"),
    f = max(n) / rank
  ) |>
  ggplot(aes(x = rank, y = n, color = type, )) +
  geom_point() +
  geom_line(aes(x = rank, y = f), linetype = 2) +
  # geom_smooth(method = "lm", se = F, alpha = .5) +
  scale_x_continuous(limits = c(1, 26^2)) +
  scale_y_log10() #+
```

```{r}

make_letter_dist <- function(corpus) {
  read.table(paste0("in/corpus/", corpus, ".txt")) |>
    tibble() |>
    filter(str_detect(V1, "^[a-z]{5,}$")) |>
    pluck("V1") |>
    str_split("") |>
    unlist() |>
    table() |>
    bind_rows() |>
    pivot_longer(cols = 1:26) |>
    mutate(value = as.numeric(value))
}

letter_dists <- make_letter_dist("linux") |>
  mutate(corpus = "linux") |>
  rbind(make_letter_dist("collins") |>
    mutate(corpus = "collins")) |>
  rbind(make_letter_dist("NWL2020") |>
    mutate(corpus = "nwl"))

letter_rankings <- letter_dists |>
  pivot_wider(names_from = corpus) |>
  mutate(total = rowSums(across(2:4))) |>
  arrange(desc(total))

letter_dists |>
  rowwise() |>
  mutate(
    rank = match(name, letter_rankings$name),
    f = letter_rankings[["total"]][[rank]] / rank
  ) |>
  ggplot(aes(x = reorder(name, rank), y = value, fill = corpus)) +
  geom_bar(stat = "identity") +
  geom_line(aes(x = rank, y = f))
```

```{r}
# what about /all/ splits?

if (!file.exists("in/cache/corpus_splits.csv")) {
  read.table("in/corpus/linux.txt") |>
    tibble() |>
    mutate(corpus = "linux") |>
    rbind(
      read.table("in/corpus/collins.txt") |>
        tibble() |>
        mutate(corpus = "collins")
    ) |>
    rbind(
      read.table("in/corpus/NWL2020.txt") |>
        tibble() |>
        mutate(corpus = "nwl")
    ) |>
    filter(str_detect(V1, "^[a-z]{5,}$")) |>
    # slice_sample(prop = .2) |>
    rowwise() |>
    mutate(
      splits = map(
        seq(1, str_length(V1) - 1), ~ paste0(
          substr(V1, ., .),
          substr(V1, . + 1, . + 1)
        )
      ) |> paste0(collapse = ",")
    ) |>
    separate_rows(splits, sep = ",") |>
    write.csv("in/cache/corpus_splits.csv")
}

# Of the 26^2 = 676 possible combinations,
# 614 are accounted for
corpus_splits <- read.csv("in/cache/corpus_splits.csv")

corpus_splits |>
  count(corpus, splits) |>
  group_by(corpus) |>
  mutate(
    rank = rank(-n, ties.method = "first"),
    f = max(n) / rank
  ) |>
  ggplot(aes(x = rank, y = n, color = corpus)) +
  geom_point() +
  geom_line(aes(y = f), linetype = 2) +
  geom_vline(aes(xintercept = 425), linetype = 3) +
  scale_x_continuous(limits = c(1, 26^2)) +
  scale_y_log10()
```

```{r}
# TODO: better gridline color
corpus_splits |>
  ggplot(aes(
    x = substr(splits, 1, 1),
    y = substr(splits, 2, 2)
  )) +
  geom_bin2d() +
  geom_bin2d(data = transform(corpus_splits, corpus = "total")) +
  coord_fixed() +
  scale_fill_continuous(type = "viridis") +
  facet_wrap(~corpus, ncol = 2)
```

```{r}
# Similar to above, but for split pairs
all_split_pairs <- dat.all() |>
  select(split = split_x, corpus) |>
  rbind(dat.all() |> select(split = split_y, corpus))

all_split_pairs |>
  ggplot(aes(
    x = substr(split, 2, 2),
    y = substr(split, 1, 1),
    fill = after_stat(count) / max(count)
  )) +
  geom_bin2d() +
  geom_bin2d(data = transform(all_split_pairs, corpus="total")) +
  coord_fixed() +
  scale_y_discrete(limits = rev(letters)) +
  scale_fill_continuous(type = "viridis") +
  facet_wrap(~corpus, ncol = 2) +
  labs() +
  theme(
    legend.position = "bottom"
  )

  
```

```{r}
## alluvial flow diagram going into and out of splits?
library(ggalluvial)

dat.all() |>
  select(word = x, split = split_x, start, end, corpus) |>
  rbind(dat.all() |>
    select(word = y, split = split_y, start, end, corpus)
  ) |>
  distinct() |>
  mutate(
    l_boundary = substr(word, start - 1, start - 1),
    r_boundary = substr(word, end + 1, end + 1),
    split_l = substr(split, 1, 1),
    split_r = substr(split, 2, 2)
  ) |>
  count(l_boundary, split_l, split_r, r_boundary) |>
  ggplot(aes(
    axis1 = l_boundary,
    axis2 = split_l,
    axis3 = split_r,
    axis4 = r_boundary,
    y = n,
    alpha = .2
  )) +
  scale_x_discrete(limits = c("Left boundary", "First split character", "Second split character", "Right boundary")) +
  geom_alluvium(curve_type = "sigmoid") +
  geom_stratum() +
  geom_text(stat = "stratum", aes(label = after_stat(stratum)))
```

```{r}
# Can I do something similar without ggalluvial?

dat.all() |>
  select(word = x, split = split_x, start, end, corpus) |>
  rbind(dat.all() |>
    select(word = y, split = split_y, start, end, corpus)
  ) |>
  mutate(
    l_boundary = substr(word, start - 1, start - 1),
    split_l = substr(split, 1, 1),
    split_r = substr(split, 2, 2),
    r_boundary = substr(word, end + 1, end + 1)
  ) |>
  count(l_boundary, split_l, split_r, r_boundary, corpus) |>
  filter(n > 250) |>
  ggplot(aes(
    x = 0,
    xend = 1,
    y = match(l_boundary, rev(letters)) |> replace_na(27),
    yend = match(split_l, rev(letters)),
    color = corpus,
    size = n / (max(n)^2),
    alpha = (n / max(n) - .1)^3 + 0.2
  )) +
  geom_segment() +
  scale_y_continuous(limits = c(rev(letters), "[prefix]"),
    sec.axis = sec_axis(~ .)
  )
```

```{r}
dat.all() |>
  filter(length <= 15) |>
  ggplot(aes(
    x = factor(length),
    y = start,
    color = corpus
  )) +
  geom_violin(scale = "width") +
  facet_wrap(~corpus, dir = "v") +
  scale_y_continuous(breaks = c(2, 4, 6, 8, 10, 12, 14, 16)) +
  theme(
    legend.position = "none"
  )
```

```{r}
# Interested in different combinations of "templates" --
# how many length + split + posn combos are there?
templates <- splits_by_type |>
  distinct(x, y, .keep_all = T) |>
  add_count(length, split_x, split_y, start, type)

templates |>
  group_by(split_x, split_y, type) |>
  arrange(desc(n)) |>
  View()
```

```{r}
# Similarly, what about coming into and out of splits?

splits_by_type |>
  filter(type == "prefix") |>
  mutate(common_first = substr(x, end + 1, end + 1)) |>
  count(common_first, split_x, split_y) |>
  arrange(desc(n))
# shows coarticulation in action!!! "im" for p, in/un for t/s...

splits_by_type |>
  filter(type == "suffix") |>
  mutate(common_last = substr(x, start - 1, start - 1)) |>
  count(common_last, split_x, split_y) |>
  arrange(desc(n))
# lots of i + declension... what else?

splits_by_type |>
  filter(type == "suffix") |>
  mutate(common_last = substr(x, start - 1, start - 1)) |>
  filter(common_last != "i") |>
  count(common_last, split_x, split_y) |>
  arrange(desc(n))
# t, s, a, e, n here with other kinds of declension
# (ed + or, nt + te)... if I were in the mood, I'd
# look for etymology too (maybe these are Latinate stems?)
```

```{r}
# vowels going into vowels
splits_by_type |>
  mutate(common_last = substr(x, start - 1, start - 1)) |>
  filter(str_detect(split_x, "^[aeiou]") | str_detect(split_y, "^[aeiou]")) |>
  filter(common_last %in% c("a", "e", "i", "o", "u")) |>
  count(common_last, split_x, split_y, type) |>
  arrange(desc(n)) #|> View()
# once scrolling past the domination of i, some interesting effects,
# esp with vowels that can double (oo, ee) -- Great Vowel Shift spellings?

splits_by_type |>
  filter(substr(x, start - 1, start - 1) == "o" &
    (substr(split_x, 1, 1) == "o" |
      substr(split_y, 1, 1) == "o")) # |> View()
# as expected, many splits with "o_" have /u/ represented by the <oo>, but
# some are even tricker due to other consonant interactions (floor/flown)

splits_by_type |>
  mutate(
    common_last = substr(x, start - 1, start - 1),
    split_x_first = substr(split_x, 1, 1),
    split_y_first = substr(split_y, 1, 1)
  ) |>
  filter(common_last %in% c("o", "e") &
    (common_last == split_x_first | common_last == split_y_first)) |>
  filter(!if_else(
    common_last == split_x_first,
    split_y_first,
    split_x_first
  ) %in% c("a", "e", "i", "o", "u")) |>
  View()

# Also introducing some neat schwa/lenition effects:
# "belay/beefy", etc.
# time to generalize this
```

```{r}
# get all rows where the:
# a) last letters of the common, and
# b) first letter of either split
# are those specified.
withLeftBoundary <- function(data, last_common_letters, first_split_letters) {
  data |>
    mutate(
      common_last = substr(x, start - 1, start - 1),
      split_x_first = substr(split_x, 1, 1),
      split_y_first = substr(split_y, 1, 1)
    ) |>
    rowwise() |>
    filter(common_last %in% last_common_letters &
      length(intersect(
        c(split_x_first, split_y_first),
        first_split_letters
      )) > 0)
}
```